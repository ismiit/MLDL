{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00f12ce",
   "metadata": {},
   "source": [
    "# *BATCH* Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a96ea2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ecca093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b1cd0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "36431e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (353,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2f33e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score ::::  0.4399387660024644\n",
      "slopes :::  [  -9.16088483 -205.46225988  516.68462383  340.62734108 -895.54360867\n",
      "  561.21453306  153.88478595  126.73431596  861.12139955   52.41982836]\n",
      "intercept :::  151.88334520854633\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.coef_)\n",
    "print('intercept ::: ',lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aca7ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDregression2 :\n",
    "    \n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.m = np.ones(X_train.shape[1])\n",
    "        self.b = 0\n",
    "        self.eta = learning_rate\n",
    "        self.iter = epochs\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            y_hat = self.b + np.dot(X_train,self.m)\n",
    "            \n",
    "            slope_b = -2 * np.mean(y_train - y_hat)\n",
    "            self.b = self.b - ( self.eta * slope_b )\n",
    "        \n",
    "            slope_m = -2 * np.dot((y_train - y_hat), X_train) / X_train.shape[0]\n",
    "            self.m = self.m - ( self.eta * slope_m )\n",
    "            \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.dot(X_test, self.m) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2396c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken ::::  0.04300260543823242\n",
      "r2_score ::::  0.45207599906646867\n",
      "slopes :::  [   7.81470012 -186.49878069  506.44993458  330.72798648  -45.79472069\n",
      " -123.85064017 -193.69645368   98.53665956  470.9589143    88.6541521 ]\n",
      "intercept :::  151.98880595777848\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.6\n",
    "epochs = 1000\n",
    "lr = GDregression2(learning_rate, epochs)\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Time taken :::: ',time.time()-start)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.m)\n",
    "print('intercept ::: ',lr.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762bbb5",
   "metadata": {},
   "source": [
    "# *STOICHASTIC* Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a3fd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken ::::  0.0019996166229248047\n",
      "r2_score ::::  0.4399387660024644\n",
      "slopes :::  [  -9.16088483 -205.46225988  516.68462383  340.62734108 -895.54360867\n",
      "  561.21453306  153.88478595  126.73431596  861.12139955   52.41982836]\n",
      "intercept :::  151.88334520854633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.coef_)\n",
    "print('intercept ::: ',lr.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4525fb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken ::::  0.5920429229736328\n",
      "r2_score ::::  0.4220621995178778\n",
      "slopes :::  [-103.15930667 -249.28947686  525.37257825  293.81684828 -481.92685052\n",
      "  377.46787546  -56.30708376  -69.95770382  837.73674502  131.08928715]\n",
      "intercept :::  149.5227885895199\n"
     ]
    }
   ],
   "source": [
    "class GDregression :\n",
    "    \n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.m = np.ones(X_train.shape[1])\n",
    "        self.b = 0\n",
    "        self.eta = learning_rate\n",
    "        self.iter = epochs\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            \n",
    "            for j in range(X_train.shape[0]):\n",
    "                \n",
    "                index = np.random.randint(0,X_train.shape[0])\n",
    "                y_hat = self.b + np.dot(X_train[index],self.m)\n",
    "            \n",
    "                slope_b = -2 * (y_train[index] - y_hat)\n",
    "                self.b = self.b - ( self.eta * slope_b )\n",
    "        \n",
    "                slope_m = -2 * np.dot((y_train[index] - y_hat), X_train[index])\n",
    "                self.m = self.m - ( self.eta * slope_m )\n",
    "               \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.dot(X_test, self.m) + self.b\n",
    "\n",
    "learning_rate = 0.6\n",
    "epochs = 105\n",
    "lr = GDregression(learning_rate, epochs)\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Time taken :::: ',time.time()-start)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.m)\n",
    "print('intercept ::: ',lr.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b376a",
   "metadata": {},
   "source": [
    "# *MINI - BATCH* Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0776537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score ::::  0.4399387660024644\n",
      "slopes :::  [  -9.16088483 -205.46225988  516.68462383  340.62734108 -895.54360867\n",
      "  561.21453306  153.88478595  126.73431596  861.12139955   52.41982836]\n",
      "intercept :::  151.88334520854633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.coef_)\n",
    "print('intercept ::: ',lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "64e81c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken ::::  0.11500096321105957\n",
      "r2_score ::::  0.4285420798045173\n",
      "slopes :::  [  27.93723251 -167.38984625  588.14065983  360.17676676 -530.58507534\n",
      "  267.60731862  -20.83957372   89.6949483   688.85778192   90.93938445]\n",
      "intercept :::  156.52414963173118\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "class GDregression3 :\n",
    "    \n",
    "    def __init__(self,batch_size,learning_rate,epochs):\n",
    "        self.m = np.ones(X_train.shape[1])\n",
    "        self.b = 0\n",
    "        self.eta = learning_rate\n",
    "        self.iter = epochs\n",
    "        self.bs = batch_size\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            \n",
    "            for j in range(int(X_train.shape[0]/self.bs)):\n",
    "                \n",
    "                index = random.sample(range(X_train.shape[0]),self.bs)\n",
    "                y_hat = self.b + np.dot(X_train[index],self.m)\n",
    "            \n",
    "                slope_b = -2 *np.mean( (y_train[index] - y_hat))\n",
    "                self.b = self.b - ( self.eta * slope_b )\n",
    "        \n",
    "                slope_m = -2 * np.dot((y_train[index] - y_hat), X_train[index])\n",
    "                self.m = self.m - ( self.eta * slope_m )\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.dot(X_test, self.m) + self.b\n",
    "\n",
    "        \n",
    "learning_rate = 0.6\n",
    "epochs = 100\n",
    "batch_size = int(X_train.shape[0]/10)\n",
    "lr = GDregression3(batch_size,learning_rate,epochs)\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Time taken :::: ',time.time()-start)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('r2_score :::: ',r2_score(y_test,y_pred))\n",
    "print('slopes ::: ', lr.m)\n",
    "print('intercept ::: ',lr.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1317d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
